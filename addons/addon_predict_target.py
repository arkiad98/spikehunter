# addons/addon_predict_target.py
# [ìˆ˜ì •] CSV ì €ì¥ ì‹œ ë°œìƒí•˜ëŠ” KeyError í•´ê²°

import os
import pandas as pd
import joblib
from datetime import datetime
import numpy as np

from modules.utils_io import read_yaml, load_partition_day, get_stock_names
from modules.utils_logger import logger

def get_latest_prediction_file(pred_path: str):
    """predictions í´ë”ì—ì„œ ê°€ì¥ ìµœì‹  ì¶”ì²œ ì¢…ëª© íŒŒì¼ì„ ì°¾ìŠµë‹ˆë‹¤."""
    if not os.path.exists(pred_path):
        return None
    
    files = [os.path.join(pred_path, f) for f in os.listdir(pred_path) if f.endswith('.csv') and '_targets' not in f]
    if not files:
        return None
        
    latest_file = max(files, key=os.path.getctime)
    return latest_file

def run_target_prediction(settings_path: str):
    """
    ML íšŒê·€ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ 'ì˜¤ëŠ˜ì˜ ì¶”ì²œ ì¢…ëª©'ì˜ ë¯¸ë˜ ê¸°ëŒ€ ìˆ˜ìµë¥ ê³¼ ëª©í‘œê°€ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """
    cfg = read_yaml(settings_path)
    paths = cfg["paths"]
    
    # 1. ì €ì¥ëœ ìµœì‹  ì¶”ì²œ ì¢…ëª© CSV íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    pred_path = paths["predictions"]
    latest_pred_file = get_latest_prediction_file(pred_path)
    
    if not latest_pred_file:
        logger.error("ì˜ˆì¸¡í•  ì¶”ì²œ ì¢…ëª© íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. '9. ì˜¤ëŠ˜ì˜ ì¶”ì²œ ì¢…ëª© ìƒì„±'ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
        
    logger.info(f"ìµœì‹  ì¶”ì²œ ì¢…ëª© íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤: {latest_pred_file}")
    
    try:
        recs_df = pd.read_csv(latest_pred_file, dtype={'code': str})
    except Exception as e:
        logger.error(f"ì¶”ì²œ ì¢…ëª© íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
        return

    latest_date = pd.to_datetime(os.path.basename(latest_pred_file).replace('.csv', ''))

    # 2. ì¶”ì²œ ì¢…ëª©ì— í•´ë‹¹í•˜ëŠ” ë‚ ì§œì˜ í”¼ì²˜ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    features_today = load_partition_day(paths["features"], latest_date, latest_date)
    if features_today.empty:
        logger.error(f"{latest_date.date()}ì˜ í”¼ì²˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
        
    # ğŸ”´ [ìˆ˜ì •] ì»¬ëŸ¼ëª… ì¶©ëŒì„ í”¼í•˜ê³  ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì¼ì›í™”í•˜ëŠ” ë¡œì§
    # ----------------------------------------------------------------------------------
    # ì¶”ì²œ ì¢…ëª© CSVì—ì„œëŠ” 'code'ì™€ ì›ë³¸ 'ml_score'ë§Œ ì‚¬ìš©í•˜ê³ ,
    # ê°€ê²©ì„ í¬í•¨í•œ ëª¨ë“  ë°ì´í„°ëŠ” í”¼ì²˜ ë°ì´í„°(features_today)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•©ë‹ˆë‹¤.
    recs_subset = recs_df[['code', 'ml_score']].copy()
    recs_subset.rename(columns={'ml_score': 'score'}, inplace=True) # ì›ë³¸ ìŠ¤ì½”ì–´ ì»¬ëŸ¼ëª… í†µì¼

    # 'inner' joinì„ ì‚¬ìš©í•˜ì—¬ ë‘ ë°ì´í„°ì— ëª¨ë‘ ì¡´ì¬í•˜ëŠ” ì¢…ëª©ë§Œ ì•ˆì „í•˜ê²Œ ë³‘í•©
    recs_with_features = pd.merge(recs_subset, features_today, on='code', how='inner')
    # ----------------------------------------------------------------------------------

    # 4. ì €ì¥ëœ íšŒê·€(Regression) ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
    logger.info("ì €ì¥ëœ ëª©í‘œê°€ ì˜ˆì¸¡ ML ëª¨ë¸(íšŒê·€)ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
    model_path = paths.get("models")
    target_model_filename = os.path.join(model_path, "target_model.joblib")
    
    if not os.path.exists(target_model_filename):
        logger.error(f"í•™ìŠµëœ ëª©í‘œê°€ ì˜ˆì¸¡ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {target_model_filename}")
        return
        
    target_model = joblib.load(target_model_filename)

    # 5. ëª¨ë¸ì´ í•™ìŠµí•œ í”¼ì²˜ë§Œ ìˆœì„œëŒ€ë¡œ ì¤€ë¹„í•˜ì—¬ ìˆ˜ìµë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    # ğŸ”´ [ìˆ˜ì •] feature_names_in_ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í˜¸í™˜ì„± í™•ë³´
    try:
        features_for_regression = recs_with_features.set_index('code').loc[:, target_model.feature_names_in_]
    except AttributeError:
        logger.error("ì˜¤ë˜ëœ ë²„ì „ì˜ ëª¨ë¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 'feature_names_in_' ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤.")
        # êµ¬ë²„ì „ ëª¨ë¸ í˜¸í™˜ì„ ìœ„í•œ ëŒ€ì²´ ë¡œì§ (í•„ìš” ì‹œ)
        # features_for_regression = recs_with_features.set_index('code').loc[:, target_model.feature_name_]
        return
        
    predicted_returns_log = target_model.predict(features_for_regression)
    # ğŸ”´ [ìˆ˜ì •] ë¡œê·¸ ìˆ˜ìµë¥ ì„ ì¼ë°˜ ìˆ˜ìµë¥ ë¡œ ë³€í™˜
    recs_with_features['predicted_ret'] = np.expm1(predicted_returns_log)
    
    # ì´ì œ 'close' ì»¬ëŸ¼ì´ recs_with_featuresì— í™•ì‹¤íˆ ì¡´ì¬í•˜ë¯€ë¡œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    recs_with_features['predicted_target_price'] = recs_with_features['close'] * (1 + recs_with_features['predicted_ret'])
    
    # 6. ìµœì¢… ê²°ê³¼ë¥¼ ì¶œë ¥í•˜ê³  CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    names = get_stock_names(recs_with_features['code'].tolist())
    recs_with_features['name'] = recs_with_features['code'].map(names)

    # --- ì½˜ì†” ì¶œë ¥ìš© ë°ì´í„°í”„ë ˆì„ ---
    df_display = recs_with_features.copy()
    df_display['predicted_ret_pct'] = (df_display['predicted_ret'] * 100).map('{:,.2f}%'.format)
    df_display['current_price'] = df_display['close'].map('{:,.0f}'.format)
    df_display['predicted_target_price'] = df_display['predicted_target_price'].map('{:,.0f}'.format)
    df_display['ml_score_clf'] = (df_display['score'] * 100).map('{:,.2f}'.format)
    
    display_cols = ['name', 'current_price', 'ml_score_clf', 'predicted_ret_pct', 'predicted_target_price']
    final_df_display = df_display.sort_values('score', ascending=False).set_index('code')[display_cols]
    
    logger.info("="*70)
    logger.info(f"     <<< {latest_date.date()} ê¸°ì¤€ ë‹¤ìŒ ì˜ì—…ì¼ ì¶”ì²œ ì¢…ëª© ëª©í‘œê°€ ì˜ˆì¸¡ >>>")
    logger.info("="*70)
    print(final_df_display.to_string())
    logger.info("="*70)

    # --- CSV ì €ì¥ìš© ë°ì´í„°í”„ë ˆì„ ---
    df_export = recs_with_features.copy()
    df_export = df_export.sort_values('score', ascending=False)
    df_export['rank'] = range(1, len(df_export) + 1)
    
    export_cols = [
        'rank', 'code', 'name', 'close', 'predicted_target_price', 'predicted_ret', 'score'
    ]
    final_df_export = df_export[export_cols]
    
    final_df_export = final_df_export.rename(columns={
        'close': 'current_price',
        'predicted_ret': 'upside_potential',
        'score': 'ml_score_clf'
    })
    
    try:
        filename = f"{latest_date.date()}_targets.csv"
        output_path = os.path.join(pred_path, filename)
        
        final_df_export.to_csv(output_path, index=False, encoding='utf-8-sig', float_format='%.4f')
        logger.info(f"ëª©í‘œê°€ ì˜ˆì¸¡ ê²°ê³¼ê°€ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        logger.error(f"ëª©í‘œê°€ ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
