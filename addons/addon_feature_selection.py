# addons/addon_feature_selection.py (v5.0)
"""
[SpikeHunter v5.0] ìµœì  í”¼ì²˜ ì¡°í•© íƒìƒ‰ê¸° (RFE Renewal)
- ê¸°ëŠ¥: ì¬ê·€ì  í”¼ì²˜ ì œê±°(RFE)ë¥¼ í†µí•´ ëª¨ë¸ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í•˜ëŠ” ìµœì†Œ/ìµœì  í”¼ì²˜ì…‹ ë°œêµ´
- ì—°ë™: v5.0 ë°ì´í„°ì…‹ ê²½ë¡œ ë° feature_registry.yaml ìƒíƒœ í‘œì‹œ ì§€ì›
"""
import os
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import average_precision_score, roc_auc_score
from tqdm import tqdm
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from datetime import datetime

from modules.utils_io import read_yaml, ensure_dir, get_user_input
from modules.utils_logger import logger
from modules.derive import _get_feature_cols
from ruamel.yaml import YAML # Safe processing

def _set_korean_font():
    font_path = 'c:/Windows/Fonts/malgun.ttf'
    if os.path.exists(font_path):
        font_name = fm.FontProperties(fname=font_path).get_name()
        plt.rc('font', family=font_name)
    plt.rcParams['axes.unicode_minus'] = False

def _get_feature_status(registry_path: str) -> dict:
    """ë ˆì§€ìŠ¤íŠ¸ë¦¬ì—ì„œ í”¼ì²˜ ìƒíƒœ(Core/Candidate) ë¡œë“œ"""
    if not os.path.exists(registry_path): return {}
    try:
        reg = read_yaml(registry_path)
        return {f['name']: f.get('status', 'unknown') for f in reg.get('features', [])}
    except: return {}

def run_feature_selection(settings_path: str):
    """RFE ì‹¤í–‰ ë©”ì¸ í•¨ìˆ˜"""
    logger.info("="*60)
    logger.info("      <<< ìµœì  í”¼ì²˜ ì¡°í•© íƒìƒ‰(RFE) ì‹œì‘ >>>")
    logger.info("="*60)
    
    cfg = read_yaml(settings_path)
    paths = cfg["paths"]
    
    # 1. ë°ì´í„° ë¡œë“œ (í‘œì¤€ ê²½ë¡œ)
    dataset_file = os.path.join(paths.get("ml_dataset", "data/proc/ml_dataset"), "ml_classification_dataset.parquet")
    if not os.path.exists(dataset_file):
        logger.error(f"ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤: {dataset_file}\në¨¼ì € 'ë°ì´í„° ê´€ë¦¬ -> ë°ì´í„°ì…‹ ìƒì„±'ì„ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    logger.info(f"ë°ì´í„° ë¡œë“œ ì¤‘... {dataset_file}")
    df = pd.read_parquet(dataset_file)
    
    # 2. í”¼ì²˜ ë° íƒ€ê²Ÿ ì„¤ì •
    # ë°ì´í„°ì…‹ì— ìˆëŠ” ëª¨ë“  ìœ íš¨ í”¼ì²˜ë¥¼ í›„ë³´ë¡œ ì‚¬ìš©
    valid_features = _get_feature_cols(df.columns)
    
    # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì •ë³´ ë¡œë“œ (ë¦¬í¬íŒ…ìš©)
    feat_status = _get_feature_status("config/feature_registry.yaml")
    
    logger.info(f"ë¶„ì„ ëŒ€ìƒ í”¼ì²˜: {len(valid_features)}ê°œ")
    
    # ìƒ˜í”Œë§ (ì†ë„ í–¥ìƒ) - ìµœê·¼ ë°ì´í„° ìœ„ì£¼ë¡œ 30ë§Œê°œë§Œ ì‚¬ìš©
    if len(df) > 300000:
        df = df.sort_values('date').tail(300000)
    
    X = df[valid_features]
    y = df['label_class']
    
    # í•™ìŠµ/ê²€ì¦ ë¶„ë¦¬ (Hold-out)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)
    
    # 3. LightGBM íŒŒë¼ë¯¸í„° (ì†ë„ ìµœì í™”)
    # [ìˆ˜ì •] CommentedMap -> dict ë³€í™˜ ë° param_space_ ì œê±°
    raw_params = cfg.get("ml_params", {}).get("lgbm_params_classification", {})
    if hasattr(raw_params, 'items'): # CommentedMap or dict
        lgbm_params = dict(raw_params)
    else:
        lgbm_params = {}

    # param_space_ ë¡œ ì‹œì‘í•˜ëŠ” í‚¤ ì œê±° (ëª¨ë¸ ì¸ìë¡œ ì „ë‹¬ë˜ì§€ ì•Šë„ë¡)
    keys_to_remove = [k for k in lgbm_params.keys() if k.startswith('param_space_')]
    for k in keys_to_remove:
        lgbm_params.pop(k)

    lgbm_params.update({'n_estimators': 500, 'verbose': -1, 'n_jobs': -1})
    
    # [NEW] 4. Baseline í‰ê°€ (í˜„ì¬ Core í”¼ì²˜)
    core_feats = [f for f, s in feat_status.items() if s == 'core']
    valid_core_feats = [f for f in core_feats if f in valid_features]
    
    baseline_score = 0.0
    if valid_core_feats:
        base_model = lgb.LGBMClassifier(**lgbm_params)
        base_model.fit(X_train[valid_core_feats], y_train)
        y_pred_base = base_model.predict_proba(X_test[valid_core_feats])[:, 1]
        baseline_score = average_precision_score(y_test, y_pred_base)
        logger.info(f" >> [Baseline] í˜„ì¬ Core í”¼ì²˜ ({len(valid_core_feats)}ê°œ) ì„±ëŠ¥(AP): {baseline_score:.4f}")
    else:
        logger.info(" >> [Baseline] Core í”¼ì²˜ê°€ ì—†ì–´ í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    # 5. RFE Loop
    features_curr = valid_features.copy()
    history = []
    
    pbar = tqdm(total=len(features_curr)-1, desc="Eliminating Features")
    
    while len(features_curr) >= 1:
        # ëª¨ë¸ í•™ìŠµ
        model = lgb.LGBMClassifier(**lgbm_params)
        model.fit(X_train[features_curr], y_train)
        
        # í‰ê°€ (Average Precision ê¸°ì¤€)
        y_pred = model.predict_proba(X_test[features_curr])[:, 1]
        score = average_precision_score(y_test, y_pred)
        
        history.append({
            'n_features': len(features_curr),
            'score': score,
            'features': features_curr.copy()
        })
        
        if len(features_curr) == 1: break
        
        # ì¤‘ìš”ë„ í•˜ìœ„ ì œê±°
        importances = pd.Series(model.feature_importances_, index=features_curr)
        worst_feature = importances.idxmin()
        features_curr.remove(worst_feature)
        pbar.update(1)
        
    pbar.close()
    
    # 6. ê²°ê³¼ ë¶„ì„
    res_df = pd.DataFrame(history).sort_values('score', ascending=False)
    best_res = res_df.iloc[0]
    
    logger.info("\n" + "="*60)
    logger.info(f"   [RFE ìµœì¢… ê²°ê³¼]")
    logger.info(f"   Baseline (í˜„ì¬): {baseline_score:.4f}")
    logger.info(f"   Best RFE (ì¶”ì²œ): {best_res['score']:.4f} (í”¼ì²˜ {best_res['n_features']}ê°œ)")
    
    diff = best_res['score'] - baseline_score
    if diff > 0:
        logger.info(f"   >> ì„±ëŠ¥ ê°œì„ : +{diff:.4f} (ê°œì„ ë¨)")
    else:
        logger.info(f"   >> ì„±ëŠ¥ ë³€í™”: {diff:.4f} (í˜„ì¬ê°€ ë” ì¢‹ê±°ë‚˜ ë¹„ìŠ·í•¨)")
    logger.info("="*60)
    
    logger.info("\n[ì¶”ì²œ í”¼ì²˜ ì¡°í•© (ì¤‘ìš”ë„ìˆœ ì •ë ¬)]")
    # ìµœì  ì¡°í•©ìœ¼ë¡œ ë‹¤ì‹œ í•™ìŠµí•´ì„œ ì¤‘ìš”ë„ ìˆœì„œëŒ€ë¡œ ì¶œë ¥
    final_feats = best_res['features']
    final_model = lgb.LGBMClassifier(**lgbm_params)
    final_model.fit(X_train[final_feats], y_train)
    final_imp = pd.Series(final_model.feature_importances_, index=final_feats).sort_values(ascending=False)
    
    for i, (feat, imp) in enumerate(final_imp.items()):
        status = feat_status.get(feat, 'unknown')
        logger.info(f" {i+1:2d}. {feat:<20} (Status: {status}) | Imp: {imp}")
        
    # 7. ì‹œê°í™”
    _set_korean_font()
    plt.figure(figsize=(10, 6))
    plt.plot(res_df['n_features'], res_df['score'], marker='o')
    plt.axvline(x=best_res['n_features'], color='r', linestyle='--', label=f"Best: {best_res['n_features']}")
    plt.axhline(y=baseline_score, color='g', linestyle=':', label=f"Baseline: {baseline_score:.4f}")
    plt.title("í”¼ì²˜ ê°œìˆ˜ì— ë”°ë¥¸ ëª¨ë¸ ì„±ëŠ¥(AP) ë³€í™”")
    plt.xlabel("í”¼ì²˜ ê°œìˆ˜")
    plt.ylabel("Average Precision")
    plt.grid(True, alpha=0.3)
    plt.legend()
    
    plot_path = "analysis_rfe_result.png"
    plt.savefig(plot_path)
    logger.info(f"\n[!] ê²°ê³¼ ì°¨íŠ¸ ì €ì¥ë¨: {plot_path}")

    # [NEW] 8. ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ (ì‚¬ìš©ì ì„ íƒ)
    print("\n" + "="*60)
    if diff > 0:
        print("ğŸ’¡ RFE ê²°ê³¼ê°€ í˜„ì¬ë³´ë‹¤ ìš°ìˆ˜í•©ë‹ˆë‹¤. ì¶”ì²œ ì¡°í•©ì„ ì ìš©í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
    else:
        print("âš ï¸ RFE ê²°ê³¼ê°€ í˜„ì¬ë³´ë‹¤ ì¢‹ì§€ ì•ŠìŠµë‹ˆë‹¤. ì ìš©ì„ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    choice = get_user_input("ìµœì  í”¼ì²˜ ì¡°í•©ì„ 'config/feature_registry.yaml'ì— ë°˜ì˜í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ")
    
    if choice.lower() == 'y':
        reg_path = "config/feature_registry.yaml"
        
        # 1. ë°±ì—…
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = f"config/feature_registry_backup_{timestamp}.yaml"
        ensure_dir("config/old") # ë°±ì—… í´ë”ê°€ ìˆìœ¼ë©´ ì¢‹ì€ë° ì—†ìœ¼ë‹ˆ ê·¸ëƒ¥ configì— or config/old?
        # ê·¸ëƒ¥ ê°™ì€ í´ë”ì—
        import shutil
        shutil.copy(reg_path, backup_path)
        logger.info(f"ë°±ì—… ì™„ë£Œ: {backup_path}")
        
        # 2. ì—…ë°ì´íŠ¸
        try:
            yaml = YAML()
            yaml.preserve_quotes = True
            
            with open(reg_path, 'r', encoding='utf-8') as f:
                data = yaml.load(f)
            
            # í”¼ì²˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            updated_count = 0
            best_feat_set = set(final_feats)
            
            if 'features' in data:
                for item in data['features']:
                    fname = item.get('name')
                    if fname:
                        if fname in best_feat_set:
                            item['status'] = 'core'
                        else:
                            # ê¸°ì¡´ì— coreì˜€ë‹¤ë©´ candidateë¡œ ê°•ë“±? ì•„ë‹ˆë©´ unused?
                            # ì‚¬ìš©ì ìš”ì²­ìƒ "ì„ íƒëœ í”¼ì²˜ë“¤ë§Œ coreë¡œ"
                            # ë‚˜ë¨¸ì§€ëŠ” unused ë˜ëŠ” candidate. ë³´í†µ unusedê°€ ì•ˆì „.
                            item['status'] = 'unused'
                        updated_count += 1
            
            with open(reg_path, 'w', encoding='utf-8') as f:
                yaml.dump(data, f)
                
            logger.info(f"ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ! ({updated_count}ê°œ í”¼ì²˜ ìƒíƒœ ë³€ê²½ë¨)")
            logger.info("ì´ì œ 'ëª¨ë¸ í•™ìŠµ' ë©”ë‰´ë¥¼ ì‹¤í–‰í•˜ë©´ ìƒˆë¡œìš´ í”¼ì²˜ ì¡°í•©ì´ ì‚¬ìš©ë©ë‹ˆë‹¤.")
            
        except Exception as e:
            logger.error(f"ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")