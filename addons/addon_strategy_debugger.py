import pandas as pd
from datetime import datetime, timedelta
import joblib
import os

from modules.utils_io import read_yaml, load_partition_day, load_index_data
from modules.utils_logger import logger

def find_latest_date_in_parquet(file_path: str) -> pd.Timestamp:
    """Parquet íŒŒì¼ ë‚´ ê°€ì¥ ìµœê·¼ ë‚ ì§œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not os.path.exists(file_path):
        return None
    try:
        # date ì»¬ëŸ¼ë§Œ ì½ì–´ì„œ ìµœëŒ€ê°’ í™•ì¸ (íš¨ìœ¨ì„±)
        df_dates = pd.read_parquet(file_path, columns=['date'])
        return df_dates['date'].max()
    except Exception as e:
        logger.error(f"ë‚ ì§œ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def run_strategy_debugger(settings_path: str):
    """
    SpikeHunter ì „ëµ(v4.0)ì˜ í•„í„°ë§ ê³¼ì •ì„ ì¶”ì í•˜ì—¬
    ë§¤ìˆ˜ ì¶”ì²œ ì¢…ëª©ì´ ì—†ëŠ” ì›ì¸ì„ ì§„ë‹¨í•©ë‹ˆë‹¤. (ML ìŠ¤ì½”ì–´ ì¤‘ì‹¬)
    """
    logger.info("\n" + "="*80)
    logger.info("      <<< SpikeHunter ì „ëµ ë””ë²„ê±° v4.0 (ML Focus) >>>")
    logger.info("="*80)

    cfg = read_yaml(settings_path)
    paths = cfg["paths"]

    # 1. ë¶„ì„í•  ìµœì‹  ë°ì´í„° ë¡œë“œ (ML Dataset ì‚¬ìš©)
    # derive.pyê°€ ìƒì„±í•œ ìµœì¢… ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ì•¼ ëª¨ë“  í”¼ì²˜ê°€ í¬í•¨ë˜ì–´ ìˆìŒ
    dataset_path = os.path.join(paths["ml_dataset"], "ml_classification_dataset.parquet")
    
    if not os.path.exists(dataset_path):
        logger.error(f"ML ë°ì´í„°ì…‹ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {dataset_path}")
        logger.error("ë©”ì¸ ë©”ë‰´ì—ì„œ '2. í”¼ì²˜ ìƒì„± ë° ë¼ë²¨ë§ (Derive)'ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return

    logger.info("ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ì—¬ ìµœì‹  ë‚ ì§œë¥¼ í™•ì¸í•©ë‹ˆë‹¤...")
    target_date = find_latest_date_in_parquet(dataset_path)
    
    if target_date is None:
        logger.error("ë°ì´í„°ì…‹ì—ì„œ ë‚ ì§œ ì •ë³´ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    logger.info(f"ğŸ” ë¶„ì„ ëŒ€ìƒ ë‚ ì§œ: {target_date.date()}")
    
    # í•´ë‹¹ ë‚ ì§œì˜ ë°ì´í„°ë§Œ ë¡œë“œ
    df_all = pd.read_parquet(dataset_path)
    df_today = df_all[df_all['date'] == target_date].copy()

    
    if df_today.empty:
        logger.error("ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìœ¼ë‚˜ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return

    # 2. íŒŒë¼ë¯¸í„° ë¡œë“œ (SpikeHunter_R1_BullStable ê¸°ì¤€)
    # v4.0 ì „ëµì€ Regime êµ¬ë¶„ ì—†ì´ ML Scoreë¥¼ ë©”ì¸ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    strategy_name = "SpikeHunter_R1_BullStable"
    if 'strategies' in cfg and strategy_name in cfg['strategies']:
        params = cfg['strategies'][strategy_name]
    else:
        logger.warning(f"ì „ëµ '{strategy_name}' ì„¤ì •ì´ ì—†ì–´ ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        params = {}
        
    ml_params = cfg.get("ml_params", {})
    threshold = params.get('min_ml_score', ml_params.get('classification_threshold', 0.4))
    
    logger.info(f"ê¸°ì¤€ ì„ê³„ê°’(Threshold): {threshold}") # min_ml_score

    # 3. ëª¨ë¸ ë¡œë“œ
    model_path = os.path.join(paths["models"], "lgbm_model.joblib")
    if not os.path.exists(model_path):
        logger.error(f"ML ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return
        
    try:
        model_clf = joblib.load(model_path)
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return

    # 4. ML ìŠ¤ì½”ì–´ ê³„ì‚°
    # feature_names_in_ í™•ì¸
    if not hasattr(model_clf, 'feature_names_in_'):
        logger.error("ëª¨ë¸ì— 'feature_names_in_' ì†ì„±ì´ ì—†ìŠµë‹ˆë‹¤. í˜¸í™˜ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ì…ë‹ˆë‹¤.")
        return

    features_needed = model_clf.feature_names_in_
    missing_cols = [c for c in features_needed if c not in df_today.columns]
    
    if missing_cols:
        logger.warning(f"ë°ì´í„°ì— ì¼ë¶€ í”¼ì²˜ê°€ ëˆ„ë½ë˜ì–´ 0ìœ¼ë¡œ ì±„ì›ë‹ˆë‹¤: {missing_cols[:5]}...")
        for c in missing_cols:
            df_today[c] = 0
            
    X = df_today[features_needed].fillna(0)
    scores = model_clf.predict_proba(X)[:, 1]
    df_today['ml_score'] = scores
    
    # 5. ê²°ê³¼ ë¶„ì„
    logger.info("\n--- [ML ìŠ¤ì½”ì–´ ë¶„ì„ ê²°ê³¼] ---")
    logger.info(f"ì „ì²´ ëŒ€ìƒ ì¢…ëª© ìˆ˜: {len(df_today)} ê°œ")
    logger.info(f"ML Score í‰ê· : {scores.mean():.4f}, ìµœëŒ€: {scores.max():.4f}, ìµœì†Œ: {scores.min():.4f}")
    
    passed_candidates = df_today[df_today['ml_score'] >= threshold].sort_values('ml_score', ascending=False)
    num_passed = len(passed_candidates)
    
    logger.info(f"ì„ê³„ê°’({threshold}) ì´ìƒ í†µê³¼ ì¢…ëª©: {num_passed} ê°œ")
    
    if num_passed > 0:
        logger.info("\n[ìƒìœ„ í›„ë³´ ì¢…ëª© TOP 10]")
        print(passed_candidates[['code', 'close', 'ml_score']].head(10).to_string(index=False))
        
        # ì¶”ê°€ ì§„ë‹¨: ë³´ìœ  ê¸°ê°„ ë‚´ ë§¤ë„ë˜ì—ˆì„ ê²½ìš° ì¶”ì • (ë°±í…ŒìŠ¤íŠ¸ ë¡œì§ ì¼ë¶€ ì°¨ìš©)
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ëª©ë¡ë§Œ ë³´ì—¬ì¤Œ
    else:
        logger.warning("\n[ì§„ë‹¨] ì„ê³„ê°’ì„ ë„˜ëŠ” ì¢…ëª©ì´ í•˜ë‚˜ë„ ì—†ìŠµë‹ˆë‹¤.")
        logger.info("  - ì‹œì¥ ìƒí™©ì´ ì¢‹ì§€ ì•Šê±°ë‚˜, ëª¨ë¸ì´ ë§¤ìš° ë³´ìˆ˜ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        logger.info("  - 'ìµœì  ì„ê³„ê°’ íƒìƒ‰(Add-on 7)'ì„ ì‹¤í–‰í•˜ì—¬ ì„ê³„ê°’ì„ ì¡°ì •í•´ë³´ì„¸ìš”.")
        
        # ì•„ì‰½ê²Œ íƒˆë½í•œ ì¢…ëª©ë“¤
        logger.info("\n[ì•„ì‰½ê²Œ íƒˆë½í•œ ìƒìœ„ ì¢…ëª© TOP 5]")
        logger.info(df_today[['code', 'close', 'ml_score']].sort_values('ml_score', ascending=False).head(5).to_string(index=False))

    logger.info("="*80)