# SpikeHunter 분류 모델 성능 분석 보고서

**문서 작성일**: 2025년 10월 8일

## 1. 분석 개요

본 문서는 SpikeHunter 프로젝트의 급등 예측 분류 모델에 대한 최신 성능 평가 결과를 분석하고, 이전 평가 결과와 비교하여 현재 모델의 특성을 진단하는 것을 목적으로 합니다. 분석 대상은 **시계열 교차검증(Time Series Cross-Validation)**을 통해 도출된 최신 성능 지표입니다.

---

## 2. 성능 요약

모델 평가 방법론 변경에 따른 주요 성능 지표 변화는 다음과 같습니다.

| 평가지표 | 이전 결과 (단순 분할) | **최신 결과 (시계열 교차검증)** | 변화 분석 |
| :--- | :---: | :---: | :--- |
| **Precision (정밀도)** | 0.5066 | **0.1542** | ▼ 크게 하락 |
| **Recall (재현율)** | 0.4200 | **0.6760** | ▲ 크게 상승 |
| **F1-Score** | 0.4593 | **0.2507** | ▼ 크게 하락 |
| **AUC** | 0.6783 | **0.6234** | - |

---

## 3. 주요 결과 분석

### 3.1. 평가 방법론의 변경: "더 어려운, 그러나 더 공정한 시험"

수치상으로 Precision과 F1-Score가 하락한 것처럼 보이지만, 이는 모델 성능의 저하가 아닌 **평가 방법론의 고도화**에 따른 자연스러운 결과입니다.

-   **이전 방식 (단순 분할)**: 시계열 데이터의 특성을 고려하지 않고 데이터를 무작위로 분할하여 평가했습니다. 이 경우, 모델이 미래의 데이터를 학습하여 과거를 예측하는 **'데이터 유출(Data Leakage)'**이 발생하여 성능이 비현실적으로 높게 측정되는 경향이 있습니다.
-   **현재 방식 (시계열 교차검증)**: 항상 과거 데이터로 미래를 예측하도록 데이터를 순차적으로 분할하여 평가합니다. 이는 실제 투자 환경을 가장 유사하게 모방하는 **업계 표준 방식**으로, 훨씬 더 어렵지만 모델의 '진짜 실력'을 정직하게 보여줍니다.

결론적으로, 현재의 낮은 점수는 **신뢰할 수 있는 현실적인 성능 기준선(Baseline)**을 확보했다는 의미에서 매우 긍정적인 진전입니다.

### 3.2. 지표별 상세 해석

-   **Precision (정밀도) 하락 (0.51 → 0.15)**: 이전의 0.51은 부풀려진 수치일 가능성이 높습니다. 현재의 0.15는 "모델이 '급등'이라고 예측했을 때, 실제로 급등할 확률이 약 15%"라는 현실적인 성능을 의미합니다. 이는 **가장 시급하게 개선해야 할 목표**입니다.

-   **Recall (재현율) 상승 (0.42 → 0.68)**: 모델이 **실제 급등한 종목의 약 68%를 성공적으로 포착**하고 있음을 의미합니다. 이는 SMOTE 오버샘플링 기법이 효과적으로 작동하여, 기회를 놓치지 않는 능력이 이전보다 향상되었음을 보여주는 긍정적인 지표입니다.

-   **종합 평가**: 현재 모델은 "급등 가능성이 있는 종목을 놓치지 않으려 넓은 그물을 던지지만(높은 재현율), 그만큼 잘못된 예측(거짓 양성)도 많이 포함하는(낮은 정밀도)" 특성을 가지고 있습니다.

---

## 4. 결론 및 권고 사항

### 4.1. 결론

현재 모델의 성능 지표 변화는 성능 저하가 아닌, **평가 방법론을 현실화함에 따라 모델의 실제 성능이 드러난 것**입니다. 우리는 이제 신뢰할 수 있는 `Precision: 0.15`, `Recall: 0.68`이라는 명확한 기준 위에서 모델 개선을 시작할 수 있습니다.

### 4.2. 권고 사항: 정밀도(Precision) 개선 전략

낮은 정밀도는 잘못된 매수 신호로 이어져 투자 손실을 유발할 수 있으므로, 다음 전략들을 통해 정밀도를 높이는 것을 최우선 목표로 삼아야 합니다.

1.  **예측 확률 임계값(Threshold) 조정 (단기, 최우선)**
    -   현재 0.5인 임계값을 0.6, 0.7 등으로 상향 조정하여, 모델이 더 강한 확신을 가질 때만 '급등'으로 예측하도록 변경합니다. 정밀도 개선에 가장 직접적이고 빠른 효과를 볼 수 있습니다.

2.  **정교한 샘플링 기법 적용 (중기)**
    -   현재 사용하는 `SMOTE` 대신, 노이즈 데이터 제거 기능이 포함된 `SMOTEENN`이나 `SMOTETomek` 같은 결합 샘플링 기법을 적용하여 모델이 더 명확한 결정 경계를 학습하도록 유도합니다.

3.  **모델 파라미터 튜닝 (중기)**
    -   LightGBM의 `scale_pos_weight` 파라미터를 SMOTE 대신 사용하거나, 규제(Regularization) 관련 파라미터를 조정하여 모델이 거짓 양성에 더 강한 페널티를 받도록 학습시킬 수 있습니다.

4.  **피처 엔지니어링 (장기)**
    -   더 변별력 높은 피처를 발굴하거나, 현재 피처 중요도 하위 피처들을 제거하여 모델이 더 명확한 신호에 집중하도록 개선합니다.