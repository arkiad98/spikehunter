# config/settings.yaml (Restore Point: AP 0.18 Version + CatBoost)

# 1. 기본 설정
top_n: 5
min_avg_value: 1000000000
fee_rate: 0.0015

backtest_defaults:
  initial_cash: 10000000.0
  default_years: 5
  min_ml_target_return: 0.03

walk_forward:
  total_start_date: '2020-01-01'
  train_months: 24
  test_months: 6

paths:
  raw_prices: d:/spikehunter/data/raw/prices
  raw_fundflow: d:/spikehunter/data/raw/fundflow
  raw_index: d:/spikehunter/data/raw/index
  merged: d:/spikehunter/data/proc/merged
  features: data/proc/features
  backtest: data/proc/backtest
  predictions: data/proc/predictions
  ml_dataset: data/proc/ml_dataset
  models: data/models
  meta: data/meta
  cache: data/cache

# 2. 머신러닝 파라미터 (이 부분이 중요!)
ml_params:
  # [최적화 결과 반영] Strategy Optimization 최적값 (Sharpe Maximize)
  # [NEW] KRX OpenAPI 인증키 (발급 후 여기에 입력)
  # 키가 있으면 OpenAPI로 지수 데이터를 수집하고, 없으면 수집을 건너뛰니다.
  krx_api_key: "9366E92B67004AC7889ED857B0A2C589C8A69D1B"

  # 데이터 수집 (2025.12.31까지 실제 데이터, 이후 예측/시뮬레이션)거래의 기대수익률(13.5%)이 높아 전체 성과는 더 우수함
  target_surge_rate: 0.06977039174197706
  stop_loss_rate: -0.025894790231361674
  target_hold_period: 5
  regression_sampling_quantile: 0.9
  classification_train_months: 24  # [Update] 27 months ago ~ 3 months ago (24m training + 3m offset)
  classification_train_end_offset: 3

  # [복구] 사용자 요청: LightGBM 단일 모델 원복
  active_model: "lgbm"

  # [복구] 최적화된 하이퍼파라미터 (AP 0.25 / Commit 2258a3f)
  # 5차 수정: 과거 Git 기록에서 추출한 Precision-Recall 최적 밸런스 설정 복원
  lgbm_params_classification:
    objective: binary
    metric: average_precision
    scale_pos_weight: 6.139907304985039 # [Restored] Exact Value
    n_estimators: 903     # [Restored] High estimators for low LR
    learning_rate: 0.005736868152224882 # [Restored] Low LR
    num_leaves: 92       # [Restored] Simple Model
    max_depth: 17          # [Restored] Shallow Depth
    colsample_bytree: 0.9847975231592317
    subsample: 0.6789116837410031

    n_jobs: -1 # [Dynamic] Handled by code
    verbose: -1

    # LightGBM용 파라미터 공간
    param_space_lgbm:
      learning_rate: {type: float, low: 0.001, high: 0.02, log: true}
      num_leaves: {type: int, low: 60, high: 255}
      max_depth: {type: int, low: 10, high: 30}
      n_estimators: {type: int, low: 500, high: 2000}
      scale_pos_weight: {type: float, low: 4.0, high: 9.0}
      colsample_bytree: {type: float, low: 0.5, high: 1.0}
      subsample: {type: float, low: 0.5, high: 1.0}
      min_child_samples: {type: int, low: 10, high: 100}
    min_child_samples: 55

  # [NEW] XGBoost 파라미터
  xgb_params_classification:
    objective: binary:logistic
    eval_metric: logloss
    n_estimators: 603
    learning_rate: 0.012649564995901032
    max_depth: 6
    subsample: 0.9790590277960377
    colsample_bytree: 0.8082325218691137
    scale_pos_weight: 2.190777004972905

    n_jobs: -1 # [Dynamic] Handled by code
    random_state: 42
    tree_method: hist
    min_child_weight: 10
    gamma: 0.19007214421560437

    # [추가] XGBoost용 파라미터 공간
    param_space_xgb:
      learning_rate: {type: float, low: 0.01, high: 0.2, log: true}
      max_depth: {type: int, low: 4, high: 12}
      n_estimators: {type: int, low: 500, high: 2000}
      scale_pos_weight: {type: float, low: 1.0, high: 4.0}
      min_child_weight: {type: int, low: 1, high: 10}
      gamma: {type: float, low: 0.0, high: 0.5}
      subsample: {type: float, low: 0.6, high: 1.0}
      colsample_bytree: {type: float, low: 0.6, high: 1.0}

  # [NEW] CatBoost 파라미터
  cat_params_classification:
    iterations: 795
    learning_rate: 0.020107281929641285
    depth: 6
    l2_leaf_reg: 2.3706494739674833
    loss_function: Logloss
    eval_metric: AUC
    random_seed: 42
    verbose: 0
    thread_count: 4
    allow_writing_files: false

    # [추가] CatBoost용 파라미터 공간
    param_space_cat:
      learning_rate: {type: float, low: 0.01, high: 0.2, log: true}
      depth: {type: int, low: 4, high: 10}
      iterations: {type: int, low: 500, high: 2000}
      l2_leaf_reg: {type: float, low: 1.0, high: 10.0}
      border_count: {type: int, low: 32, high: 255}
      random_strength: {type: float, low: 0.0, high: 10.0}
    border_count: 159
    random_strength: 0.5607904698110447

# 4. 전략 최적화 설정
  classification_threshold: 0.29148933887406403
optimization:
  SpikeHunter_R1_BullStable:
    optimize_on: Hybrid_Stability
    n_trials: 100
    param_space:
      target_r: {type: float, low: 0.06, high: 0.10} # [Refined] WFO Optimized Range (Center 8-9%)
      stop_r: {type: float, low: -0.05, high: -0.025} # [Refined] WFO Optimized Range (Include -4~-5%)
      min_ml_score: {type: float, low: 0.20, high: 0.60} # [Correction] User reported scores > 0.50, expanded range
      max_market_vol: {type: float, low: 0.015, high: 0.04}
      vbo_k: {type: float, low: 0.3, high: 0.7}
      min_mfi: {type: float, low: 40.0, high: 60.0}

# 5. 전략 설정
strategies:
  SpikeHunter_R1_BullStable:
    name: SpikeHunter_R1_BullStable
    target_r: 0.06977039174197706 # [수정] 예측력 우선 초기값
    stop_r: -0.025894790231361674 # [수정] 하한 -5%
    max_hold: 5
    min_ml_score: 0.29148933887406403 # [수정] 무난한 시작값
    vbo_k: 0.44546026507313446
    max_market_vol: 0.016067488935397216
    min_mfi: 56.19434719373056
    min_obv_slope: 0
    top_n: 5


